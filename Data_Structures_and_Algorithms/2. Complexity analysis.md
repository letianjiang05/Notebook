# 2.1   Algorithm efficiency assessment
- Objective: 
    - Finding a Solution to the Problem
    - Seeking the Optimal Solution
- 2 dimensions:
    - Time efficiency
    - Space efficiency
# 2.2 Iteration and recursion
## 2.2.1   Iteration
### 1.   For loops
```python
for i in range(1, n + 1):
```
```C++
for (int i = 1; i <= n; ++i) {
}
```
### 2.   While loops
```python
while i <= n:
```
```C++
while (i <= n) {
}
```
### 
## 2.2.2   Recursion
- 2 Phases:
    - Calling Phase
    - Returning Phase
- 3 Elements:
    - Termination Condition
    - Recursive Call
    - Return Result
```python
def recur(n: int) -> int:
    """Recursion"""
    # Termination condition
    if n == 1:
        return 1
    # Recursive: recursive call
    res = recur(n - 1)
    # Return: return result
    return n + res
```
```C++
/* Recursion */
int recur(int n) {
    // Termination condition
    if (n == 1)
        return 1;
    // Recursive: recursive call
    int res = recur(n - 1);
    // Return: return result
    return n + res;
}
```

||Interation|Recursion|
|---|---|---|
||from the bottom up|from the top down|
||$ f(1), f(2) $|$ f(n) = f(n - 1) + n $|
|Approach|Loop structure|Function calls itself|
|Time Efficiency|Generally higher efficiency, no function call overhead|Each function call generates overhead|
|Memory Usage|Typically uses a fixed size of memory space|Accumulative function calls can use a substantial amount of stack frame space|
|Suitable Problems|Suitable for simple loop tasks, intuitive and readable code|Suitable for problem decomposition, like trees, graphs, divide-and-conquer, backtracking, etc., concise and clear code structure|

### 2.2.2.1 Call Stack
- Every time a recursive function calls itself, the system allocates memory for the newly initiated function to store local variables, the return address, and other relevant information.
- recursion generally consumes **more memory space** than iteration.
- recursion is usually **less time-efficient** than loops.

### 2.2.2.2 Tail Recursion
A function performs its recursive call as the very last step before returning
### 2.2.2.3 Recursion Trees

# 2.3  Time complexity
1. Determining the Running Platform
2. Evaluating the Run Time for Various Computational Operations
3. Counting All the Computational Operations in the Code

## 2.3.1 Time Growth Trends
- Constant Time: O(1)
- Linear Time: O(n)
- Quadratic Time: O(n^2)

## 2.3.2 Asymptotic upper bound
- $ \exists \, c > 0, n_0 \geq 0: \forall n \geq n_0, T(n) \leq c f(n) $
- then $ f(n) $ is an asymptotic upper bound of $ T(n) $: $O(f(n))$

## 2.3.3 Calculation Method
1. Count the number of operations
2. determining the asymptotic upper bound
## Common types of time complexity
|Type|Notation||
|---|---|---|
|Constant|O(1)||
|Log|O(log n)|Halving Each Round|
|Linear|O(n)||
|Linear-Log|O(n log n)|Nested Loops|
|Quadratic|O(n^2)||
|Exp|O(2^n)|Cell Division: $ 2^0 + 2^1 + ... + 2^{n-1} = 2^n - 1 $|
|Factorial|O(n!)|Full Permutation, Recursion|
# 2.4 Space complexity
- 3 Types
    - Input Space (Usually Ignored)
    - Temporary Space
        - Temporary data
        - Stack Frame Space
        - Instruction Space
    - Output Space
- Worst Case
    - worst input data
    - peak memory used during the algorithm's execution